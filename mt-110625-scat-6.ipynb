{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1291e0be",
   "metadata": {
    "_cell_guid": "ff090894-7853-4044-83fb-771c8b01a6b2",
    "_uuid": "554324d4-79c1-4d25-9b3c-931c65c2e4a5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-11T14:59:50.131378Z",
     "iopub.status.busy": "2025-06-11T14:59:50.130979Z",
     "iopub.status.idle": "2025-06-11T15:08:57.389625Z",
     "shell.execute_reply": "2025-06-11T15:08:57.387681Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 547.268189,
     "end_time": "2025-06-11T15:08:57.391551",
     "exception": false,
     "start_time": "2025-06-11T14:59:50.123362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m356.8/356.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 15:00:26.944791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749654027.246912      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749654027.331188      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Model Testing Configuration\n",
      "ğŸ“ Model path: /kaggle/input/mt-100625-scat-4/thesis_models/streaming_hallucination_aware_atc_model.pt\n",
      "ğŸ–¥ï¸  Device: cpu\n",
      "ğŸ“Š Output path: ./model_test_results\n",
      "ğŸ“ Starting Comprehensive Model Testing for ML Hallucination Research\n",
      "================================================================================\n",
      "ğŸ“ Generating Test Scenarios...\n",
      "âœ… Generated 180 test scenarios:\n",
      "   - Normal scenarios: 100\n",
      "   - Edge case scenarios: 50\n",
      "   - Stress test scenarios: 30\n",
      "ğŸ¤– Loading Trained Model...\n",
      "ğŸ”„ Loading model from /kaggle/input/mt-100625-scat-4/thesis_models/streaming_hallucination_aware_atc_model.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19537f8f000f41abaf652f711eeb2584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf32510130c540628dc1fa649ec73916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f79804eb7543749f92b87c198e1db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2e0a0ab1c9441a8e92ca56d107832f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8a52fc343642dcb609b19897bb8946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Running Comprehensive Evaluation...\n",
      "ğŸ§ª Starting Comprehensive Model Evaluation\n",
      "============================================================\n",
      "ğŸ“Š Test Dataset: 180 scenarios\n",
      "   - Normal: 100\n",
      "   - Edge cases: 80\n",
      "   - Outside envelope: 66\n",
      "1ï¸âƒ£ Basic Performance Evaluation...\n",
      "   âœ… Conflict Detection Accuracy: 0.750\n",
      "   âœ… Conflict Detection F1: 0.643\n",
      "   âœ… Clearance Prediction Accuracy: 0.206\n",
      "   âœ… Average Confidence: 0.991\n",
      "2ï¸âƒ£ Uncertainty Analysis...\n",
      "   âœ… Average Uncertainty (Conflicts): 0.075\n",
      "   âœ… Average Uncertainty (Safe): 0.051\n",
      "3ï¸âƒ£ Hallucination Detection Analysis...\n",
      "   âœ… Hallucination Detection Accuracy: 0.633\n",
      "   âœ… Hallucination Detection F1: 0.000\n",
      "4ï¸âƒ£ Edge Case Analysis...\n",
      "5ï¸âƒ£ Calibration Analysis...\n",
      "   âœ… Calibration Error: 0.241\n",
      "6ï¸âƒ£ Generating Comprehensive Report...\n",
      "ğŸ“Š Generating comprehensive report...\n",
      "ğŸ“ Report saved to: ./model_test_results\n",
      "âœ… Comprehensive evaluation completed!\n",
      "âœˆï¸ Testing BlueSky Integration...\n",
      "âœˆï¸ Simulating 20 test flight scenarios...\n",
      "   âœ… Scenario 000: SAFE (P=0.004, U=0.031)\n",
      "   âœ… Scenario 001: SAFE (P=0.004, U=0.031)\n",
      "   âœ… Scenario 002: SAFE (P=0.004, U=0.033)\n",
      "   âœ… Scenario 003: SAFE (P=0.005, U=0.034)\n",
      "   âœ… Scenario 004: SAFE (P=0.004, U=0.030)\n",
      "   âœ… Scenario 005: SAFE (P=0.004, U=0.036)\n",
      "   âœ… Scenario 006: SAFE (P=0.004, U=0.031)\n",
      "   âœ… Scenario 007: SAFE (P=0.004, U=0.034)\n",
      "   âœ… Scenario 008: SAFE (P=0.004, U=0.034)\n",
      "   âœ… Scenario 009: SAFE (P=0.004, U=0.031)\n",
      "   âœ… Scenario 010: SAFE (P=0.004, U=0.036)\n",
      "   âœ… Scenario 011: SAFE (P=0.004, U=0.033)\n",
      "   âœ… Scenario 012: SAFE (P=0.004, U=0.034)\n",
      "   âœ… Scenario 013: SAFE (P=0.004, U=0.034)\n",
      "   âœ… Scenario 014: SAFE (P=0.004, U=0.035)\n",
      "   âœ… Scenario 015: SAFE (P=0.005, U=0.036)\n",
      "   âœ… Scenario 016: SAFE (P=0.004, U=0.035)\n",
      "   âœ… Scenario 017: SAFE (P=0.005, U=0.030)\n",
      "   âœ… Scenario 018: SAFE (P=0.005, U=0.034)\n",
      "   âœ… Scenario 019: SAFE (P=0.004, U=0.035)\n",
      "ğŸ“ Simulation log saved to simulation_log.json\n",
      "\n",
      "ğŸ¯ COMPREHENSIVE TESTING SUMMARY\n",
      "==================================================\n",
      "âœ… Model Performance:\n",
      "   - Conflict Detection Accuracy: 0.750\n",
      "   - Average Confidence: 0.991\n",
      "   - Hallucination Detection Accuracy: 0.633\n",
      "\n",
      "ğŸ“Š Edge Case Analysis:\n",
      "\n",
      "ğŸŒ¡ï¸ Uncertainty Analysis:\n",
      "   - Avg Uncertainty (Conflicts): 0.075\n",
      "   - Avg Uncertainty (Safe): 0.051\n",
      "\n",
      "âœˆï¸ BlueSky Simulation:\n",
      "   - 0/20 scenarios predicted as conflicts\n",
      "   - Average confidence: 0.996\n",
      "\n",
      "ğŸ“ All results saved to: ./model_test_results\n",
      "ğŸ“ Comprehensive model testing completed!\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive ML Model Testing Framework for ATC Hallucination Research\n",
    "# End-to-End Model Evaluation and Validation Pipeline\n",
    "\n",
    "# BlueSky integration\n",
    "BLUESKY_AVAILABLE = True\n",
    "try:\n",
    "    import bluesky\n",
    "    BLUESKY_AVAILABLE = True\n",
    "    print(\"âœ… BlueSky available\")\n",
    "except ImportError:\n",
    "    !pip -qq install bluesky\n",
    "\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, f1_score, \n",
    "    precision_recall_curve, roc_curve, auc\n",
    ")\n",
    "\n",
    "from sklearn.calibration import calibration_curve \n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration for testing\n",
    "@dataclass\n",
    "class TestConfig:\n",
    "    \"\"\"Testing configuration\"\"\"\n",
    "    model_path: str = \"/kaggle/input/mt-100625-scat-4/thesis_models/streaming_hallucination_aware_atc_model.pt\"\n",
    "    model_name: str = \"distilbert-base-uncased\"\n",
    "    max_sequence_length: int = 128\n",
    "    batch_size: int = 8\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Test parameters\n",
    "    mc_dropout_samples: int = 20\n",
    "    confidence_threshold: float = 0.8\n",
    "    uncertainty_threshold: float = 0.3\n",
    "    \n",
    "    # Conflict thresholds\n",
    "    conflict_threshold_nm: float = 5.0\n",
    "    conflict_threshold_ft: float = 1000.0\n",
    "    \n",
    "    # Training envelope bounds (for hallucination testing)\n",
    "    altitude_min: float = 10000  # ft\n",
    "    altitude_max: float = 50000  # ft\n",
    "    speed_min: float = 200  # kt\n",
    "    speed_max: float = 600  # kt\n",
    "    \n",
    "    # Output paths\n",
    "    output_path: str = \"./model_test_results\"\n",
    "\n",
    "test_config = TestConfig()\n",
    "os.makedirs(test_config.output_path, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ§ª Model Testing Configuration\")\n",
    "print(f\"ğŸ“ Model path: {test_config.model_path}\")\n",
    "print(f\"ğŸ–¥ï¸  Device: {test_config.device}\")\n",
    "print(f\"ğŸ“Š Output path: {test_config.output_path}\")\n",
    "\n",
    "# Recreate the model architecture\n",
    "class FixedHallucinationAwareATCModel(nn.Module):\n",
    "    \"\"\"Recreate the exact model architecture for loading\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, num_clearance_types: int, dropout_rate: float = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = DistilBertModel.from_pretrained(model_name)\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        # Main task heads\n",
    "        self.conflict_head = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size // 2, 2)\n",
    "        )\n",
    "        \n",
    "        self.resolution_head = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size // 2, num_clearance_types)\n",
    "        )\n",
    "        \n",
    "        # Hallucination detection head\n",
    "        self.hallucination_head = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size // 4, 1)\n",
    "        )\n",
    "        \n",
    "        self.dropout_rate = dropout_rate\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, enable_dropout=False):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]\n",
    "        \n",
    "        if enable_dropout:\n",
    "            pooled_output = F.dropout(pooled_output, p=self.dropout_rate, training=True)\n",
    "        \n",
    "        conflict_logits = self.conflict_head(pooled_output)\n",
    "        resolution_logits = self.resolution_head(pooled_output)\n",
    "        hallucination_logits = self.hallucination_head(pooled_output)\n",
    "        \n",
    "        return conflict_logits, resolution_logits, hallucination_logits\n",
    "    \n",
    "    def get_uncertainty_estimates(self, input_ids, attention_mask, n_samples=20):\n",
    "        \"\"\"Estimate model uncertainty using Monte Carlo dropout\"\"\"\n",
    "        self.train()  # Enable dropout\n",
    "        \n",
    "        conflict_samples = []\n",
    "        resolution_samples = []\n",
    "        hallucination_samples = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(n_samples):\n",
    "                conflict_logits, resolution_logits, hallucination_logits = self.forward(\n",
    "                    input_ids, attention_mask, enable_dropout=True\n",
    "                )\n",
    "                conflict_samples.append(F.softmax(conflict_logits, dim=-1))\n",
    "                resolution_samples.append(F.softmax(resolution_logits, dim=-1))\n",
    "                hallucination_samples.append(torch.sigmoid(hallucination_logits))\n",
    "        \n",
    "        # Calculate statistics\n",
    "        conflict_probs = torch.stack(conflict_samples)\n",
    "        resolution_probs = torch.stack(resolution_samples)\n",
    "        hallucination_probs = torch.stack(hallucination_samples)\n",
    "        \n",
    "        results = {\n",
    "            'conflict_mean': conflict_probs.mean(dim=0),\n",
    "            'conflict_std': conflict_probs.std(dim=0),\n",
    "            'conflict_entropy': -torch.sum(conflict_probs.mean(dim=0) * torch.log(conflict_probs.mean(dim=0) + 1e-8), dim=-1),\n",
    "            'resolution_mean': resolution_probs.mean(dim=0),\n",
    "            'resolution_std': resolution_probs.std(dim=0),\n",
    "            'hallucination_mean': hallucination_probs.mean(dim=0),\n",
    "            'hallucination_std': hallucination_probs.std(dim=0)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test scenario generator\n",
    "class ATCTestScenarioGenerator:\n",
    "    \"\"\"Generate comprehensive test scenarios for model evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self, config: TestConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def generate_normal_scenarios(self, n_scenarios: int = 100) -> pd.DataFrame:\n",
    "        \"\"\"Generate scenarios within normal operational envelope\"\"\"\n",
    "        scenarios = []\n",
    "        \n",
    "        for i in range(n_scenarios):\n",
    "            # Normal operating parameters\n",
    "            alt1 = np.random.uniform(20000, 40000)  # Normal cruise altitudes\n",
    "            alt2 = np.random.uniform(20000, 40000)\n",
    "            speed1 = np.random.uniform(350, 550)    # Normal cruise speeds\n",
    "            speed2 = np.random.uniform(350, 550)\n",
    "            heading1 = np.random.uniform(0, 360)\n",
    "            heading2 = np.random.uniform(0, 360)\n",
    "            \n",
    "            # Various separation scenarios\n",
    "            if i < n_scenarios // 3:  # Safe separations\n",
    "                h_dist = np.random.uniform(10, 50)\n",
    "                v_dist = np.random.uniform(2000, 5000)\n",
    "                conflict = False\n",
    "            elif i < 2 * n_scenarios // 3:  # Close but safe\n",
    "                h_dist = np.random.uniform(6, 10)\n",
    "                v_dist = np.random.uniform(1200, 2000)\n",
    "                conflict = False\n",
    "            else:  # Conflicts\n",
    "                h_dist = np.random.uniform(1, 4.9)\n",
    "                v_dist = np.random.uniform(100, 900)\n",
    "                conflict = True\n",
    "            \n",
    "            clearance_type = np.random.choice(['none', 'altitude_change', 'heading_change', 'speed_change'])\n",
    "            \n",
    "            scenario = {\n",
    "                'scenario_id': f'normal_{i:03d}',\n",
    "                'scenario_type': 'normal',\n",
    "                'altitude_1': alt1,\n",
    "                'altitude_2': alt2,\n",
    "                'speed_1': speed1,\n",
    "                'speed_2': speed2,\n",
    "                'heading_1': heading1,\n",
    "                'heading_2': heading2,\n",
    "                'horizontal_distance': h_dist,\n",
    "                'vertical_distance': v_dist,\n",
    "                'conflict': conflict,\n",
    "                'clearance_type': clearance_type,\n",
    "                'outside_envelope': False\n",
    "            }\n",
    "            scenarios.append(scenario)\n",
    "        \n",
    "        return pd.DataFrame(scenarios)\n",
    "    \n",
    "    def generate_edge_case_scenarios(self, n_scenarios: int = 50) -> pd.DataFrame:\n",
    "        \"\"\"Generate edge case scenarios for hallucination testing\"\"\"\n",
    "        scenarios = []\n",
    "        \n",
    "        for i in range(n_scenarios):\n",
    "            scenario_type = np.random.choice(['extreme_altitude', 'extreme_speed', 'extreme_separation'])\n",
    "            \n",
    "            if scenario_type == 'extreme_altitude':\n",
    "                # Outside normal altitude envelope\n",
    "                alt1 = np.random.choice([\n",
    "                    np.random.uniform(5000, 9999),    # Too low\n",
    "                    np.random.uniform(50001, 60000)   # Too high\n",
    "                ])\n",
    "                alt2 = np.random.uniform(20000, 40000)  # Normal\n",
    "                speed1 = np.random.uniform(350, 550)\n",
    "                speed2 = np.random.uniform(350, 550)\n",
    "                outside_envelope = True\n",
    "                \n",
    "            elif scenario_type == 'extreme_speed':\n",
    "                # Outside normal speed envelope\n",
    "                alt1 = np.random.uniform(20000, 40000)\n",
    "                alt2 = np.random.uniform(20000, 40000)\n",
    "                speed1 = np.random.choice([\n",
    "                    np.random.uniform(100, 199),      # Too slow\n",
    "                    np.random.uniform(601, 800)       # Too fast\n",
    "                ])\n",
    "                speed2 = np.random.uniform(350, 550)\n",
    "                outside_envelope = True\n",
    "                \n",
    "            else:  # extreme_separation\n",
    "                # Extreme separation scenarios\n",
    "                alt1 = np.random.uniform(20000, 40000)\n",
    "                alt2 = np.random.uniform(20000, 40000)\n",
    "                speed1 = np.random.uniform(350, 550)\n",
    "                speed2 = np.random.uniform(350, 550)\n",
    "                outside_envelope = False\n",
    "            \n",
    "            heading1 = np.random.uniform(0, 360)\n",
    "            heading2 = np.random.uniform(0, 360)\n",
    "            \n",
    "            # Extreme separations\n",
    "            if scenario_type == 'extreme_separation':\n",
    "                h_dist = np.random.choice([\n",
    "                    np.random.uniform(0.1, 0.9),      # Very close\n",
    "                    np.random.uniform(100, 200)       # Very far\n",
    "                ])\n",
    "                v_dist = np.random.choice([\n",
    "                    np.random.uniform(10, 50),        # Very close vertically\n",
    "                    np.random.uniform(10000, 20000)   # Very far vertically\n",
    "                ])\n",
    "            else:\n",
    "                h_dist = np.random.uniform(5, 15)\n",
    "                v_dist = np.random.uniform(1000, 3000)\n",
    "            \n",
    "            conflict = h_dist < self.config.conflict_threshold_nm and v_dist < self.config.conflict_threshold_ft\n",
    "            clearance_type = np.random.choice(['none', 'altitude_change', 'heading_change', 'speed_change'])\n",
    "            \n",
    "            scenario = {\n",
    "                'scenario_id': f'edge_{i:03d}',\n",
    "                'scenario_type': scenario_type,\n",
    "                'altitude_1': alt1,\n",
    "                'altitude_2': alt2,\n",
    "                'speed_1': speed1,\n",
    "                'speed_2': speed2,\n",
    "                'heading_1': heading1,\n",
    "                'heading_2': heading2,\n",
    "                'horizontal_distance': h_dist,\n",
    "                'vertical_distance': v_dist,\n",
    "                'conflict': conflict,\n",
    "                'clearance_type': clearance_type,\n",
    "                'outside_envelope': outside_envelope\n",
    "            }\n",
    "            scenarios.append(scenario)\n",
    "        \n",
    "        return pd.DataFrame(scenarios)\n",
    "    \n",
    "    def generate_stress_test_scenarios(self, n_scenarios: int = 30) -> pd.DataFrame:\n",
    "        \"\"\"Generate stress test scenarios with extreme parameters\"\"\"\n",
    "        scenarios = []\n",
    "        \n",
    "        for i in range(n_scenarios):\n",
    "            # Extreme parameters outside any reasonable envelope\n",
    "            alt1 = np.random.choice([\n",
    "                np.random.uniform(1000, 4999),       # Very low\n",
    "                np.random.uniform(60001, 80000)      # Very high\n",
    "            ])\n",
    "            alt2 = np.random.choice([\n",
    "                np.random.uniform(1000, 4999),\n",
    "                np.random.uniform(60001, 80000)\n",
    "            ])\n",
    "            \n",
    "            speed1 = np.random.choice([\n",
    "                np.random.uniform(50, 99),           # Very slow\n",
    "                np.random.uniform(801, 1000)         # Very fast\n",
    "            ])\n",
    "            speed2 = np.random.choice([\n",
    "                np.random.uniform(50, 99),\n",
    "                np.random.uniform(801, 1000)\n",
    "            ])\n",
    "            \n",
    "            heading1 = np.random.uniform(0, 360)\n",
    "            heading2 = np.random.uniform(0, 360)\n",
    "            \n",
    "            # Extreme separations\n",
    "            h_dist = np.random.choice([\n",
    "                np.random.uniform(0.01, 0.5),        # Collision imminent\n",
    "                np.random.uniform(500, 1000)         # Extremely far\n",
    "            ])\n",
    "            v_dist = np.random.choice([\n",
    "                np.random.uniform(1, 25),            # Collision imminent\n",
    "                np.random.uniform(50000, 100000)     # Extremely far\n",
    "            ])\n",
    "            \n",
    "            conflict = h_dist < self.config.conflict_threshold_nm and v_dist < self.config.conflict_threshold_ft\n",
    "            clearance_type = np.random.choice(['none', 'altitude_change', 'heading_change', 'speed_change'])\n",
    "            \n",
    "            scenario = {\n",
    "                'scenario_id': f'stress_{i:03d}',\n",
    "                'scenario_type': 'stress_test',\n",
    "                'altitude_1': alt1,\n",
    "                'altitude_2': alt2,\n",
    "                'speed_1': speed1,\n",
    "                'speed_2': speed2,\n",
    "                'heading_1': heading1,\n",
    "                'heading_2': heading2,\n",
    "                'horizontal_distance': h_dist,\n",
    "                'vertical_distance': v_dist,\n",
    "                'conflict': conflict,\n",
    "                'clearance_type': clearance_type,\n",
    "                'outside_envelope': True\n",
    "            }\n",
    "            scenarios.append(scenario)\n",
    "        \n",
    "        return pd.DataFrame(scenarios)\n",
    "\n",
    "# Test dataset for model evaluation\n",
    "class ModelTestDataset(Dataset):\n",
    "    \"\"\"Dataset for model testing with various scenario types\"\"\"\n",
    "    \n",
    "    def __init__(self, scenarios_df: pd.DataFrame, tokenizer, max_length: int = 128):\n",
    "        self.scenarios_df = scenarios_df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Encode clearance types (need to match training)\n",
    "        unique_clearances = ['none', 'altitude_change', 'heading_change', 'speed_change', 'other']\n",
    "        self.clearance_encoder = LabelEncoder()\n",
    "        self.clearance_encoder.fit(unique_clearances)\n",
    "        \n",
    "        self.scenarios_df['clearance_label'] = self.clearance_encoder.transform(\n",
    "            self.scenarios_df['clearance_type'].fillna('none')\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ“Š Test Dataset: {len(self.scenarios_df)} scenarios\")\n",
    "        print(f\"   - Normal: {(self.scenarios_df['scenario_type'] == 'normal').sum()}\")\n",
    "        print(f\"   - Edge cases: {(self.scenarios_df['scenario_type'] != 'normal').sum()}\")\n",
    "        print(f\"   - Outside envelope: {self.scenarios_df['outside_envelope'].sum()}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.scenarios_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.scenarios_df.iloc[idx]\n",
    "        \n",
    "        # Create scenario description\n",
    "        text = self._create_scenario_text(row)\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'conflict_label': torch.tensor(1 if row['conflict'] else 0, dtype=torch.long),\n",
    "            'clearance_label': torch.tensor(row['clearance_label'], dtype=torch.long),\n",
    "            'envelope_violation': torch.tensor(float(row['outside_envelope']), dtype=torch.float),\n",
    "            'scenario_id': row['scenario_id'],\n",
    "            'scenario_type': row['scenario_type']\n",
    "        }\n",
    "    \n",
    "    def _create_scenario_text(self, row):\n",
    "        \"\"\"Create natural language scenario description\"\"\"\n",
    "        text = (\n",
    "            f\"Aircraft A at FL{int(row['altitude_1']/100):03d} \"\n",
    "            f\"heading {int(row['heading_1']):03d}Â° \"\n",
    "            f\"speed {int(row['speed_1']):03d} kt; \"\n",
    "            f\"Aircraft B at FL{int(row['altitude_2']/100):03d} \"\n",
    "            f\"heading {int(row['heading_2']):03d}Â° \"\n",
    "            f\"speed {int(row['speed_2']):03d} kt; \"\n",
    "            f\"horizontal separation {row['horizontal_distance']:.1f} NM; \"\n",
    "            f\"vertical separation {row['vertical_distance']:.0f} ft.\"\n",
    "        )\n",
    "        return text\n",
    "\n",
    "# Comprehensive model evaluator\n",
    "class ComprehensiveModelEvaluator:\n",
    "    \"\"\"Comprehensive evaluation of the trained ATC model\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str, config: TestConfig):\n",
    "        self.config = config\n",
    "        self.model = self._load_model(model_path)\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(config.model_name)\n",
    "        self.results = {}\n",
    "        \n",
    "    def _load_model(self, model_path: str):\n",
    "        \"\"\"Load the trained model\"\"\"\n",
    "        try:\n",
    "            print(f\"ğŸ”„ Loading model from {model_path}\")\n",
    "            \n",
    "            # Initialize model with correct parameters (from training)\n",
    "            model = FixedHallucinationAwareATCModel(\n",
    "                model_name=self.config.model_name,\n",
    "                num_clearance_types=2  # Based on training output\n",
    "            )\n",
    "            \n",
    "            # Load state dict\n",
    "            state_dict = torch.load(model_path, map_location=self.config.device)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(self.config.device)\n",
    "            model.eval()\n",
    "            \n",
    "            print(\"âœ… Model loaded successfully\")\n",
    "            return model\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def evaluate_comprehensive(self, test_scenarios: pd.DataFrame):\n",
    "        \"\"\"Run comprehensive evaluation\"\"\"\n",
    "        print(\"ğŸ§ª Starting Comprehensive Model Evaluation\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Create test dataset\n",
    "        test_dataset = ModelTestDataset(test_scenarios, self.tokenizer, self.config.max_sequence_length)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size, shuffle=False)\n",
    "        \n",
    "        # Run evaluations\n",
    "        print(\"1ï¸âƒ£ Basic Performance Evaluation...\")\n",
    "        basic_results = self._evaluate_basic_performance(test_loader)\n",
    "        \n",
    "        print(\"2ï¸âƒ£ Uncertainty Analysis...\")\n",
    "        uncertainty_results = self._evaluate_uncertainty(test_loader)\n",
    "        \n",
    "        print(\"3ï¸âƒ£ Hallucination Detection Analysis...\")\n",
    "        hallucination_results = self._evaluate_hallucination_detection(test_loader)\n",
    "        \n",
    "        print(\"4ï¸âƒ£ Edge Case Analysis...\")\n",
    "        edge_case_results = self._evaluate_edge_cases(test_loader, test_scenarios)\n",
    "        \n",
    "        print(\"5ï¸âƒ£ Calibration Analysis...\")\n",
    "        calibration_results = self._evaluate_calibration(test_loader)\n",
    "        \n",
    "        # Combine results\n",
    "        self.results = {\n",
    "            'basic_performance': basic_results,\n",
    "            'uncertainty_analysis': uncertainty_results,\n",
    "            'hallucination_detection': hallucination_results,\n",
    "            'edge_case_analysis': edge_case_results,\n",
    "            'calibration_analysis': calibration_results\n",
    "        }\n",
    "        \n",
    "        print(\"6ï¸âƒ£ Generating Comprehensive Report...\")\n",
    "        self._generate_comprehensive_report()\n",
    "        \n",
    "        print(\"âœ… Comprehensive evaluation completed!\")\n",
    "        return self.results\n",
    "    \n",
    "    def _evaluate_basic_performance(self, test_loader):\n",
    "        \"\"\"Evaluate basic model performance\"\"\"\n",
    "        all_conflict_preds = []\n",
    "        all_conflict_labels = []\n",
    "        all_clearance_preds = []\n",
    "        all_clearance_labels = []\n",
    "        all_scenario_types = []\n",
    "        all_confidences = []\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                input_ids = batch['input_ids'].to(self.config.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.config.device)\n",
    "                \n",
    "                conflict_logits, clearance_logits, _ = self.model(input_ids, attention_mask)\n",
    "                \n",
    "                # Predictions\n",
    "                conflict_probs = F.softmax(conflict_logits, dim=-1)\n",
    "                clearance_probs = F.softmax(clearance_logits, dim=-1)\n",
    "                \n",
    "                conflict_preds = torch.argmax(conflict_logits, dim=-1)\n",
    "                clearance_preds = torch.argmax(clearance_logits, dim=-1)\n",
    "                \n",
    "                # Collect results\n",
    "                all_conflict_preds.extend(conflict_preds.cpu().numpy())\n",
    "                all_conflict_labels.extend(batch['conflict_label'].numpy())\n",
    "                all_clearance_preds.extend(clearance_preds.cpu().numpy())\n",
    "                all_clearance_labels.extend(batch['clearance_label'].numpy())\n",
    "                all_scenario_types.extend(batch['scenario_type'])\n",
    "                all_confidences.extend(torch.max(conflict_probs, dim=-1)[0].cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        results = {\n",
    "            'conflict_accuracy': np.mean(np.array(all_conflict_preds) == np.array(all_conflict_labels)),\n",
    "            'conflict_f1': f1_score(all_conflict_labels, all_conflict_preds, average='weighted'),\n",
    "            'clearance_accuracy': np.mean(np.array(all_clearance_preds) == np.array(all_clearance_labels)),\n",
    "            'clearance_f1': f1_score(all_clearance_labels, all_clearance_preds, average='weighted'),\n",
    "            'average_confidence': np.mean(all_confidences),\n",
    "            'predictions': {\n",
    "                'conflict_preds': all_conflict_preds,\n",
    "                'conflict_labels': all_conflict_labels,\n",
    "                'clearance_preds': all_clearance_preds,\n",
    "                'clearance_labels': all_clearance_labels,\n",
    "                'scenario_types': all_scenario_types,\n",
    "                'confidences': all_confidences\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Conflict Detection Accuracy: {results['conflict_accuracy']:.3f}\")\n",
    "        print(f\"   âœ… Conflict Detection F1: {results['conflict_f1']:.3f}\")\n",
    "        print(f\"   âœ… Clearance Prediction Accuracy: {results['clearance_accuracy']:.3f}\")\n",
    "        print(f\"   âœ… Average Confidence: {results['average_confidence']:.3f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_uncertainty(self, test_loader):\n",
    "        \"\"\"Evaluate uncertainty estimation using Monte Carlo dropout\"\"\"\n",
    "        all_uncertainties = []\n",
    "        all_labels = []\n",
    "        all_scenario_types = []\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(self.config.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.config.device)\n",
    "            \n",
    "            # Get uncertainty estimates\n",
    "            uncertainty_estimates = self.model.get_uncertainty_estimates(\n",
    "                input_ids, attention_mask, n_samples=self.config.mc_dropout_samples\n",
    "            )\n",
    "            \n",
    "            # Extract uncertainty metrics\n",
    "            conflict_entropy = uncertainty_estimates['conflict_entropy'].cpu().numpy()\n",
    "            conflict_std = uncertainty_estimates['conflict_std'].cpu().numpy().mean(axis=1)\n",
    "            \n",
    "            all_uncertainties.extend(conflict_entropy + conflict_std)  # Combined uncertainty\n",
    "            all_labels.extend(batch['conflict_label'].numpy())\n",
    "            all_scenario_types.extend(batch['scenario_type'])\n",
    "        \n",
    "        results = {\n",
    "            'uncertainties': all_uncertainties,\n",
    "            'labels': all_labels,\n",
    "            'scenario_types': all_scenario_types,\n",
    "            'high_uncertainty_threshold': np.percentile(all_uncertainties, 90),\n",
    "            'avg_uncertainty_conflict': np.mean([u for u, l in zip(all_uncertainties, all_labels) if l == 1]),\n",
    "            'avg_uncertainty_safe': np.mean([u for u, l in zip(all_uncertainties, all_labels) if l == 0])\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Average Uncertainty (Conflicts): {results['avg_uncertainty_conflict']:.3f}\")\n",
    "        print(f\"   âœ… Average Uncertainty (Safe): {results['avg_uncertainty_safe']:.3f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_hallucination_detection(self, test_loader):\n",
    "        \"\"\"Evaluate hallucination detection capabilities\"\"\"\n",
    "        all_hallucination_preds = []\n",
    "        all_envelope_violations = []\n",
    "        all_scenario_types = []\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                input_ids = batch['input_ids'].to(self.config.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.config.device)\n",
    "                \n",
    "                _, _, hallucination_logits = self.model(input_ids, attention_mask)\n",
    "                hallucination_probs = torch.sigmoid(hallucination_logits.squeeze(-1))\n",
    "                \n",
    "                all_hallucination_preds.extend(hallucination_probs.cpu().numpy())\n",
    "                all_envelope_violations.extend(batch['envelope_violation'].numpy())\n",
    "                all_scenario_types.extend(batch['scenario_type'])\n",
    "        \n",
    "        # Calculate metrics\n",
    "        binary_preds = np.array(all_hallucination_preds) > 0.5\n",
    "        results = {\n",
    "            'hallucination_accuracy': np.mean(binary_preds == np.array(all_envelope_violations)),\n",
    "            'hallucination_f1': f1_score(all_envelope_violations, binary_preds) if len(set(all_envelope_violations)) > 1 else 0,\n",
    "            'predictions': all_hallucination_preds,\n",
    "            'labels': all_envelope_violations,\n",
    "            'scenario_types': all_scenario_types\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Hallucination Detection Accuracy: {results['hallucination_accuracy']:.3f}\")\n",
    "        print(f\"   âœ… Hallucination Detection F1: {results['hallucination_f1']:.3f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_edge_cases(self, test_loader, test_scenarios):\n",
    "        \"\"\"Evaluate performance on edge cases\"\"\"\n",
    "        # Group by scenario type\n",
    "        scenario_performance = {}\n",
    "        \n",
    "        basic_results = self.results.get('basic_performance', {})\n",
    "        if not basic_results:\n",
    "            return {}\n",
    "        \n",
    "        preds = basic_results['predictions']\n",
    "        \n",
    "        for scenario_type in test_scenarios['scenario_type'].unique():\n",
    "            type_mask = np.array(preds['scenario_types']) == scenario_type\n",
    "            \n",
    "            if np.sum(type_mask) > 0:\n",
    "                type_conflict_labels = np.array(preds['conflict_labels'])[type_mask]\n",
    "                type_conflict_preds = np.array(preds['conflict_preds'])[type_mask]\n",
    "                type_confidences = np.array(preds['confidences'])[type_mask]\n",
    "                \n",
    "                scenario_performance[scenario_type] = {\n",
    "                    'count': np.sum(type_mask),\n",
    "                    'accuracy': np.mean(type_conflict_preds == type_conflict_labels),\n",
    "                    'avg_confidence': np.mean(type_confidences),\n",
    "                    'f1_score': f1_score(type_conflict_labels, type_conflict_preds, average='weighted') if len(set(type_conflict_labels)) > 1 else 0\n",
    "                }\n",
    "        \n",
    "        print(f\"   âœ… Edge Case Analysis Complete\")\n",
    "        for scenario_type, metrics in scenario_performance.items():\n",
    "            print(f\"      {scenario_type}: Accuracy={metrics['accuracy']:.3f}, Confidence={metrics['avg_confidence']:.3f}\")\n",
    "        \n",
    "        return scenario_performance\n",
    "    \n",
    "    def _evaluate_calibration(self, test_loader):\n",
    "        \"\"\"Evaluate model calibration\"\"\"\n",
    "        all_confidences = []\n",
    "        all_correct = []\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                input_ids = batch['input_ids'].to(self.config.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.config.device)\n",
    "                \n",
    "                conflict_logits, _, _ = self.model(input_ids, attention_mask)\n",
    "                conflict_probs = F.softmax(conflict_logits, dim=-1)\n",
    "                \n",
    "                max_probs, preds = torch.max(conflict_probs, dim=-1)\n",
    "                correct = (preds == batch['conflict_label'].to(self.config.device))\n",
    "                \n",
    "                all_confidences.extend(max_probs.cpu().numpy())\n",
    "                all_correct.extend(correct.cpu().numpy())\n",
    "        \n",
    "        # Calculate calibration\n",
    "        try:\n",
    "            fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "                all_correct, all_confidences, n_bins=10\n",
    "            )\n",
    "            calibration_error = np.mean(np.abs(fraction_of_positives - mean_predicted_value))\n",
    "        except:\n",
    "            calibration_error = float('nan')\n",
    "            fraction_of_positives = []\n",
    "            mean_predicted_value = []\n",
    "        \n",
    "        results = {\n",
    "            'calibration_error': calibration_error,\n",
    "            'confidences': all_confidences,\n",
    "            'correct': all_correct,\n",
    "            'fraction_of_positives': fraction_of_positives,\n",
    "            'mean_predicted_value': mean_predicted_value\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Calibration Error: {calibration_error:.3f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _generate_comprehensive_report(self):\n",
    "        \"\"\"Generate comprehensive evaluation report with visualizations\"\"\"\n",
    "        print(\"ğŸ“Š Generating comprehensive report...\")\n",
    "        \n",
    "        # Create visualizations\n",
    "        self._plot_performance_metrics()\n",
    "        self._plot_uncertainty_analysis()\n",
    "        self._plot_edge_case_analysis()\n",
    "        self._plot_calibration_analysis()\n",
    "        \n",
    "        # Generate summary report\n",
    "        self._generate_summary_report()\n",
    "        \n",
    "        print(f\"ğŸ“ Report saved to: {self.config.output_path}\")\n",
    "    \n",
    "    def _plot_performance_metrics(self):\n",
    "        \"\"\"Plot performance metrics\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        basic_results = self.results['basic_performance']\n",
    "        preds = basic_results['predictions']\n",
    "        \n",
    "        # Confusion matrix for conflict detection\n",
    "        cm_conflict = confusion_matrix(preds['conflict_labels'], preds['conflict_preds'])\n",
    "        sns.heatmap(cm_conflict, annot=True, fmt='d', ax=axes[0,0], cmap='Blues')\n",
    "        axes[0,0].set_title('Conflict Detection Confusion Matrix')\n",
    "        axes[0,0].set_xlabel('Predicted')\n",
    "        axes[0,0].set_ylabel('Actual')\n",
    "        \n",
    "        # Confidence distribution\n",
    "        axes[0,1].hist(preds['confidences'], bins=30, alpha=0.7, color='skyblue')\n",
    "        axes[0,1].set_title('Confidence Distribution')\n",
    "        axes[0,1].set_xlabel('Confidence')\n",
    "        axes[0,1].set_ylabel('Frequency')\n",
    "        \n",
    "        # Performance by scenario type\n",
    "        scenario_types = list(set(preds['scenario_types']))\n",
    "        accuracies = []\n",
    "        for stype in scenario_types:\n",
    "            type_mask = np.array(preds['scenario_types']) == stype\n",
    "            if np.sum(type_mask) > 0:\n",
    "                type_accuracy = np.mean(\n",
    "                    np.array(preds['conflict_preds'])[type_mask] == \n",
    "                    np.array(preds['conflict_labels'])[type_mask]\n",
    "                )\n",
    "                accuracies.append(type_accuracy)\n",
    "            else:\n",
    "                accuracies.append(0)\n",
    "        \n",
    "        axes[1,0].bar(scenario_types, accuracies, color='lightgreen')\n",
    "        axes[1,0].set_title('Accuracy by Scenario Type')\n",
    "        axes[1,0].set_xlabel('Scenario Type')\n",
    "        axes[1,0].set_ylabel('Accuracy')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Confidence vs Accuracy\n",
    "        conf_bins = np.linspace(0, 1, 11)\n",
    "        bin_accuracies = []\n",
    "        for i in range(len(conf_bins)-1):\n",
    "            mask = (np.array(preds['confidences']) >= conf_bins[i]) & (np.array(preds['confidences']) < conf_bins[i+1])\n",
    "            if np.sum(mask) > 0:\n",
    "                bin_acc = np.mean(\n",
    "                    np.array(preds['conflict_preds'])[mask] == \n",
    "                    np.array(preds['conflict_labels'])[mask]\n",
    "                )\n",
    "                bin_accuracies.append(bin_acc)\n",
    "            else:\n",
    "                bin_accuracies.append(0)\n",
    "        \n",
    "        axes[1,1].plot(conf_bins[:-1], bin_accuracies, 'o-', color='red')\n",
    "        axes[1,1].plot([0, 1], [0, 1], '--', color='gray', alpha=0.5)\n",
    "        axes[1,1].set_title('Reliability Diagram')\n",
    "        axes[1,1].set_xlabel('Confidence')\n",
    "        axes[1,1].set_ylabel('Accuracy')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.config.output_path, 'performance_metrics.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def _plot_uncertainty_analysis(self):\n",
    "        \"\"\"Plot uncertainty analysis\"\"\"\n",
    "        uncertainty_results = self.results['uncertainty_analysis']\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Uncertainty by label\n",
    "        conflict_uncertainties = [u for u, l in zip(uncertainty_results['uncertainties'], uncertainty_results['labels']) if l == 1]\n",
    "        safe_uncertainties = [u for u, l in zip(uncertainty_results['uncertainties'], uncertainty_results['labels']) if l == 0]\n",
    "        \n",
    "        axes[0].hist(safe_uncertainties, bins=30, alpha=0.7, label='Safe Scenarios', color='green')\n",
    "        axes[0].hist(conflict_uncertainties, bins=30, alpha=0.7, label='Conflict Scenarios', color='red')\n",
    "        axes[0].set_title('Uncertainty Distribution by Label')\n",
    "        axes[0].set_xlabel('Uncertainty')\n",
    "        axes[0].set_ylabel('Frequency')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Uncertainty by scenario type\n",
    "        scenario_types = list(set(uncertainty_results['scenario_types']))\n",
    "        scenario_uncertainties = []\n",
    "        for stype in scenario_types:\n",
    "            type_uncertainties = [u for u, s in zip(uncertainty_results['uncertainties'], uncertainty_results['scenario_types']) if s == stype]\n",
    "            if type_uncertainties:\n",
    "                scenario_uncertainties.append(np.mean(type_uncertainties))\n",
    "            else:\n",
    "                scenario_uncertainties.append(0)\n",
    "        \n",
    "        axes[1].bar(scenario_types, scenario_uncertainties, color='orange')\n",
    "        axes[1].set_title('Average Uncertainty by Scenario Type')\n",
    "        axes[1].set_xlabel('Scenario Type')\n",
    "        axes[1].set_ylabel('Average Uncertainty')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.config.output_path, 'uncertainty_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def _plot_edge_case_analysis(self):\n",
    "        \"\"\"Plot edge case analysis\"\"\"\n",
    "        edge_results = self.results['edge_case_analysis']\n",
    "        \n",
    "        scenario_types = list(edge_results.keys())\n",
    "        accuracies = [edge_results[st]['accuracy'] for st in scenario_types]\n",
    "        confidences = [edge_results[st]['avg_confidence'] for st in scenario_types]\n",
    "        counts = [edge_results[st]['count'] for st in scenario_types]\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # Accuracy by scenario type\n",
    "        bars1 = axes[0].bar(scenario_types, accuracies, color='lightblue')\n",
    "        axes[0].set_title('Accuracy by Scenario Type')\n",
    "        axes[0].set_xlabel('Scenario Type')\n",
    "        axes[0].set_ylabel('Accuracy')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, acc in zip(bars1, accuracies):\n",
    "            height = bar.get_height()\n",
    "            axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                        f'{acc:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Confidence by scenario type\n",
    "        bars2 = axes[1].bar(scenario_types, confidences, color='lightcoral')\n",
    "        axes[1].set_title('Average Confidence by Scenario Type')\n",
    "        axes[1].set_xlabel('Scenario Type')\n",
    "        axes[1].set_ylabel('Average Confidence')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        for bar, conf in zip(bars2, confidences):\n",
    "            height = bar.get_height()\n",
    "            axes[1].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                        f'{conf:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Sample count\n",
    "        bars3 = axes[2].bar(scenario_types, counts, color='lightgreen')\n",
    "        axes[2].set_title('Sample Count by Scenario Type')\n",
    "        axes[2].set_xlabel('Scenario Type')\n",
    "        axes[2].set_ylabel('Count')\n",
    "        axes[2].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        for bar, count in zip(bars3, counts):\n",
    "            height = bar.get_height()\n",
    "            axes[2].text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                        f'{count}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.config.output_path, 'edge_case_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def _plot_calibration_analysis(self):\n",
    "        \"\"\"Plot calibration analysis\"\"\"\n",
    "        calib_results = self.results['calibration_analysis']\n",
    "        \n",
    "        if len(calib_results['fraction_of_positives']) > 0:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "            \n",
    "            # Calibration plot\n",
    "            axes[0].plot(calib_results['mean_predicted_value'], calib_results['fraction_of_positives'], 'o-', label='Model')\n",
    "            axes[0].plot([0, 1], [0, 1], '--', color='gray', label='Perfect Calibration')\n",
    "            axes[0].set_xlabel('Mean Predicted Probability')\n",
    "            axes[0].set_ylabel('Fraction of Positives')\n",
    "            axes[0].set_title('Calibration Plot')\n",
    "            axes[0].legend()\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Confidence histogram\n",
    "            axes[1].hist(calib_results['confidences'], bins=30, alpha=0.7, color='purple')\n",
    "            axes[1].set_title('Confidence Distribution')\n",
    "            axes[1].set_xlabel('Confidence')\n",
    "            axes[1].set_ylabel('Frequency')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(self.config.output_path, 'calibration_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "    \n",
    "    def _generate_summary_report(self):\n",
    "        \"\"\"Generate summary report\"\"\"\n",
    "        report = []\n",
    "        report.append(\"# Comprehensive Model Evaluation Report\")\n",
    "        report.append(\"=\" * 50)\n",
    "        report.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # Basic Performance\n",
    "        basic = self.results['basic_performance']\n",
    "        report.append(\"## Basic Performance Metrics\")\n",
    "        report.append(f\"- Conflict Detection Accuracy: {basic['conflict_accuracy']:.3f}\")\n",
    "        report.append(f\"- Conflict Detection F1 Score: {basic['conflict_f1']:.3f}\")\n",
    "        report.append(f\"- Clearance Prediction Accuracy: {basic['clearance_accuracy']:.3f}\")\n",
    "        report.append(f\"- Clearance Prediction F1 Score: {basic['clearance_f1']:.3f}\")\n",
    "        report.append(f\"- Average Model Confidence: {basic['average_confidence']:.3f}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # Uncertainty Analysis\n",
    "        uncertainty = self.results['uncertainty_analysis']\n",
    "        report.append(\"## Uncertainty Analysis\")\n",
    "        report.append(f\"- Average Uncertainty (Conflicts): {uncertainty['avg_uncertainty_conflict']:.3f}\")\n",
    "        report.append(f\"- Average Uncertainty (Safe): {uncertainty['avg_uncertainty_safe']:.3f}\")\n",
    "        report.append(f\"- High Uncertainty Threshold (90th percentile): {uncertainty['high_uncertainty_threshold']:.3f}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # Hallucination Detection\n",
    "        hallucination = self.results['hallucination_detection']\n",
    "        report.append(\"## Hallucination Detection\")\n",
    "        report.append(f\"- Hallucination Detection Accuracy: {hallucination['hallucination_accuracy']:.3f}\")\n",
    "        report.append(f\"- Hallucination Detection F1 Score: {hallucination['hallucination_f1']:.3f}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # Edge Case Analysis\n",
    "        edge_cases = self.results['edge_case_analysis']\n",
    "        report.append(\"## Edge Case Performance\")\n",
    "        for scenario_type, metrics in edge_cases.items():\n",
    "            report.append(f\"- {scenario_type}:\")\n",
    "            report.append(f\"  - Sample Count: {metrics['count']}\")\n",
    "            report.append(f\"  - Accuracy: {metrics['accuracy']:.3f}\")\n",
    "            report.append(f\"  - Average Confidence: {metrics['avg_confidence']:.3f}\")\n",
    "            report.append(f\"  - F1 Score: {metrics['f1_score']:.3f}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # Calibration\n",
    "        calibration = self.results['calibration_analysis']\n",
    "        report.append(\"## Model Calibration\")\n",
    "        report.append(f\"- Calibration Error: {calibration['calibration_error']:.3f}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # Save report\n",
    "        with open(os.path.join(self.config.output_path, 'evaluation_report.md'), 'w') as f:\n",
    "            f.write('\\n'.join(report))\n",
    "\n",
    "# BlueSky Integration for Real-time Testing\n",
    "class BlueSkyModelIntegration:\n",
    "    \"\"\"Integration with BlueSky simulator for real-time model testing\"\"\"\n",
    "    \n",
    "    def __init__(self, model_evaluator: ComprehensiveModelEvaluator):\n",
    "        self.evaluator = model_evaluator\n",
    "        self.simulation_log = []\n",
    "        \n",
    "    def create_test_scenario(self, aircraft_data: List[Dict]) -> str:\n",
    "        \"\"\"Create scenario text from aircraft data\"\"\"\n",
    "        if len(aircraft_data) < 2:\n",
    "            return \"\"\n",
    "        \n",
    "        ac1, ac2 = aircraft_data[0], aircraft_data[1]\n",
    "        \n",
    "        # Calculate separations\n",
    "        h_dist = self._calculate_horizontal_distance(ac1, ac2)\n",
    "        v_dist = abs(ac1['altitude'] - ac2['altitude'])\n",
    "        \n",
    "        text = (\n",
    "            f\"Aircraft A at FL{int(ac1['altitude']/100):03d} \"\n",
    "            f\"heading {int(ac1['heading']):03d}Â° \"\n",
    "            f\"speed {int(ac1['speed']):03d} kt; \"\n",
    "            f\"Aircraft B at FL{int(ac2['altitude']/100):03d} \"\n",
    "            f\"heading {int(ac2['heading']):03d}Â° \"\n",
    "            f\"speed {int(ac2['speed']):03d} kt; \"\n",
    "            f\"horizontal separation {h_dist:.1f} NM; \"\n",
    "            f\"vertical separation {v_dist:.0f} ft.\"\n",
    "        )\n",
    "        return text\n",
    "    \n",
    "    def _calculate_horizontal_distance(self, ac1: Dict, ac2: Dict) -> float:\n",
    "        \"\"\"Calculate horizontal distance between aircraft\"\"\"\n",
    "        # Simplified distance calculation (should use proper haversine for real implementation)\n",
    "        lat_diff = ac1['latitude'] - ac2['latitude']\n",
    "        lon_diff = ac1['longitude'] - ac2['longitude']\n",
    "        return np.sqrt(lat_diff**2 + lon_diff**2) * 60  # Rough conversion to NM\n",
    "    \n",
    "    def real_time_conflict_detection(self, aircraft_data: List[Dict]) -> Dict:\n",
    "        \"\"\"Perform real-time conflict detection\"\"\"\n",
    "        scenario_text = self.create_test_scenario(aircraft_data)\n",
    "        \n",
    "        if not scenario_text:\n",
    "            return {'error': 'Insufficient aircraft data'}\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.evaluator.tokenizer(\n",
    "            scenario_text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.evaluator.config.max_sequence_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].to(self.evaluator.config.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.evaluator.config.device)\n",
    "        \n",
    "        # Get model predictions\n",
    "        self.evaluator.model.eval()\n",
    "        with torch.no_grad():\n",
    "            conflict_logits, clearance_logits, hallucination_logits = self.evaluator.model(\n",
    "                input_ids, attention_mask\n",
    "            )\n",
    "            \n",
    "            # Get uncertainty estimates\n",
    "            uncertainty_estimates = self.evaluator.model.get_uncertainty_estimates(\n",
    "                input_ids, attention_mask, n_samples=10\n",
    "            )\n",
    "            \n",
    "            conflict_probs = F.softmax(conflict_logits, dim=-1)\n",
    "            clearance_probs = F.softmax(clearance_logits, dim=-1)\n",
    "            hallucination_prob = torch.sigmoid(hallucination_logits)\n",
    "            \n",
    "            result = {\n",
    "                'conflict_probability': conflict_probs[0, 1].item(),  # Probability of conflict\n",
    "                'conflict_prediction': bool(conflict_probs[0, 1] > 0.5),\n",
    "                'confidence': torch.max(conflict_probs[0]).item(),\n",
    "                'recommended_clearance': int(torch.argmax(clearance_logits[0]).item()),\n",
    "                'hallucination_risk': hallucination_prob[0].item(),\n",
    "                'uncertainty': uncertainty_estimates['conflict_entropy'][0].item(),\n",
    "                'scenario_text': scenario_text,\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            # Log the result\n",
    "            self.simulation_log.append(result)\n",
    "            \n",
    "            return result\n",
    "    \n",
    "    def simulate_test_flights(self, n_scenarios: int = 20):\n",
    "        \"\"\"Simulate test flights for real-time testing\"\"\"\n",
    "        print(f\"âœˆï¸ Simulating {n_scenarios} test flight scenarios...\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i in range(n_scenarios):\n",
    "            # Generate random aircraft data\n",
    "            aircraft_data = [\n",
    "                {\n",
    "                    'id': f'TEST{i:03d}A',\n",
    "                    'latitude': 59.0 + np.random.uniform(-2, 2),\n",
    "                    'longitude': 18.0 + np.random.uniform(-2, 2),\n",
    "                    'altitude': np.random.uniform(20000, 40000),\n",
    "                    'speed': np.random.uniform(350, 550),\n",
    "                    'heading': np.random.uniform(0, 360)\n",
    "                },\n",
    "                {\n",
    "                    'id': f'TEST{i:03d}B',\n",
    "                    'latitude': 59.0 + np.random.uniform(-2, 2),\n",
    "                    'longitude': 18.0 + np.random.uniform(-2, 2),\n",
    "                    'altitude': np.random.uniform(20000, 40000),\n",
    "                    'speed': np.random.uniform(350, 550),\n",
    "                    'heading': np.random.uniform(0, 360)\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            result = self.real_time_conflict_detection(aircraft_data)\n",
    "            results.append(result)\n",
    "            \n",
    "            if result['conflict_prediction']:\n",
    "                print(f\"   ğŸš¨ Scenario {i:03d}: CONFLICT detected (P={result['conflict_probability']:.3f}, U={result['uncertainty']:.3f})\")\n",
    "            else:\n",
    "                print(f\"   âœ… Scenario {i:03d}: SAFE (P={result['conflict_probability']:.3f}, U={result['uncertainty']:.3f})\")\n",
    "        \n",
    "        # Save simulation log\n",
    "        import json\n",
    "        with open(os.path.join(self.evaluator.config.output_path, 'simulation_log.json'), 'w') as f:\n",
    "            json.dump(self.simulation_log, f, indent=2)\n",
    "        \n",
    "        print(f\"ğŸ“ Simulation log saved to simulation_log.json\")\n",
    "        return results\n",
    "\n",
    "# Main execution function\n",
    "def run_comprehensive_model_test():\n",
    "    \"\"\"Run the complete model testing pipeline\"\"\"\n",
    "    print(\"ğŸ“ Starting Comprehensive Model Testing for ML Hallucination Research\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Initialize scenario generator\n",
    "    print(\"ğŸ“ Generating Test Scenarios...\")\n",
    "    scenario_generator = ATCTestScenarioGenerator(test_config)\n",
    "    \n",
    "    # Generate different types of scenarios\n",
    "    normal_scenarios = scenario_generator.generate_normal_scenarios(n_scenarios=100)\n",
    "    edge_scenarios = scenario_generator.generate_edge_case_scenarios(n_scenarios=50)\n",
    "    stress_scenarios = scenario_generator.generate_stress_test_scenarios(n_scenarios=30)\n",
    "    \n",
    "    # Combine all scenarios\n",
    "    all_scenarios = pd.concat([normal_scenarios, edge_scenarios, stress_scenarios], ignore_index=True)\n",
    "    \n",
    "    print(f\"âœ… Generated {len(all_scenarios)} test scenarios:\")\n",
    "    print(f\"   - Normal scenarios: {len(normal_scenarios)}\")\n",
    "    print(f\"   - Edge case scenarios: {len(edge_scenarios)}\")\n",
    "    print(f\"   - Stress test scenarios: {len(stress_scenarios)}\")\n",
    "    \n",
    "    # Initialize model evaluator\n",
    "    print(\"ğŸ¤– Loading Trained Model...\")\n",
    "    try:\n",
    "        evaluator = ComprehensiveModelEvaluator(test_config.model_path, test_config)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load model: {e}\")\n",
    "        print(\"ğŸ’¡ Make sure the model path is correct and the model file exists\")\n",
    "        return\n",
    "    \n",
    "    # Run comprehensive evaluation\n",
    "    print(\"ğŸ§ª Running Comprehensive Evaluation...\")\n",
    "    results = evaluator.evaluate_comprehensive(all_scenarios)\n",
    "    \n",
    "    # BlueSky integration testing\n",
    "    print(\"âœˆï¸ Testing BlueSky Integration...\")\n",
    "    bluesky_integration = BlueSkyModelIntegration(evaluator)\n",
    "    simulation_results = bluesky_integration.simulate_test_flights(n_scenarios=20)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\nğŸ¯ COMPREHENSIVE TESTING SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"âœ… Model Performance:\")\n",
    "    print(f\"   - Conflict Detection Accuracy: {results['basic_performance']['conflict_accuracy']:.3f}\")\n",
    "    print(f\"   - Average Confidence: {results['basic_performance']['average_confidence']:.3f}\")\n",
    "    print(f\"   - Hallucination Detection Accuracy: {results['hallucination_detection']['hallucination_accuracy']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Edge Case Analysis:\")\n",
    "    for scenario_type, metrics in results['edge_case_analysis'].items():\n",
    "        print(f\"   - {scenario_type}: Accuracy={metrics['accuracy']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nğŸŒ¡ï¸ Uncertainty Analysis:\")\n",
    "    print(f\"   - Avg Uncertainty (Conflicts): {results['uncertainty_analysis']['avg_uncertainty_conflict']:.3f}\")\n",
    "    print(f\"   - Avg Uncertainty (Safe): {results['uncertainty_analysis']['avg_uncertainty_safe']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nâœˆï¸ BlueSky Simulation:\")\n",
    "    conflict_count = sum(1 for r in simulation_results if r['conflict_prediction'])\n",
    "    print(f\"   - {conflict_count}/{len(simulation_results)} scenarios predicted as conflicts\")\n",
    "    print(f\"   - Average confidence: {np.mean([r['confidence'] for r in simulation_results]):.3f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ All results saved to: {test_config.output_path}\")\n",
    "    print(\"ğŸ“ Comprehensive model testing completed!\")\n",
    "    \n",
    "    return results, simulation_results\n",
    "\n",
    "# Execute the comprehensive testing\n",
    "if __name__ == \"__main__\":\n",
    "    results, simulation_results = run_comprehensive_model_test()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 244853697,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 555.586231,
   "end_time": "2025-06-11T15:09:00.463384",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-11T14:59:44.877153",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b76f4cb3bff44a8b70fa83348260301": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0c9ec67db63742a8ac46cf9d5a2fbe4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_38b1cacee7f843bd9c93c8a83a0a1a1a",
       "max": 466062.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_94acd96a759c4fb08fae26d262a980de",
       "tabbable": null,
       "tooltip": null,
       "value": 466062.0
      }
     },
     "19537f8f000f41abaf652f711eeb2584": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e21ee4a2daf04bb8910505b2d493cca3",
        "IPY_MODEL_f9fae800ab044116852c2954a652d20e",
        "IPY_MODEL_2abc3acaa8cd4077b3677960c902832a"
       ],
       "layout": "IPY_MODEL_8c32ca99ce75426f926cf87310be5e1d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1b3f63a5282449698f9c0dc7f27ed8fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20c630aff59a4f7d871aa34ad9bce1be": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "249d0ef1cd9c4e87b37499fe1bb66d94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2abc3acaa8cd4077b3677960c902832a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_20c630aff59a4f7d871aa34ad9bce1be",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_4dd0d9caaf8349bb887781ac3c772342",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡483/483â€‡[00:00&lt;00:00,â€‡41.8kB/s]"
      }
     },
     "31a40d2df05d468dab412c38b8fb88ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "38b1cacee7f843bd9c93c8a83a0a1a1a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "443179ef3be54f1bbb64440f5b032c40": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4dbff1aacf774e26b4d3ce22daba0f42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4dd0d9caaf8349bb887781ac3c772342": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "53fb2f41ba4c4236823e4730e14c5485": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54d8fd79cc3a444aa143ca2d0bccf53b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5930f9a01f124df095ddfa0a9d66d9d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_443179ef3be54f1bbb64440f5b032c40",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_4dbff1aacf774e26b4d3ce22daba0f42",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡48.0/48.0â€‡[00:00&lt;00:00,â€‡4.48kB/s]"
      }
     },
     "5c39e53cab064625aae044f4794880e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d4070a3050b4e9db4accd3d38d8781a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a0f9484c223147bc968f0087be0a7f82",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_f1dc6e09b6244270acf7d94b7776510c",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:â€‡100%"
      }
     },
     "6b2c318e66fd429ba18c98d7b5eabbc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8bfb01ba7f344287aa65bd4ab747c055",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_249d0ef1cd9c4e87b37499fe1bb66d94",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:â€‡100%"
      }
     },
     "6da7c8102b2a4d5b8c78501b7196a279": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6e45da5bec834a57a208e3f47db9cb61": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e8a52fc343642dcb609b19897bb8946": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f3f76e03857e4945ac35828f00e4b764",
        "IPY_MODEL_0c9ec67db63742a8ac46cf9d5a2fbe4b",
        "IPY_MODEL_852ad25b40764aa69c1478b1fb0af4db"
       ],
       "layout": "IPY_MODEL_fffa980ad107493db2f739b1a5c331ee",
       "tabbable": null,
       "tooltip": null
      }
     },
     "705c1109473c4667bd937a368254dcd9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76894ca1f3204d7abc4011f3d0b651ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7b6792d1831244eea821066680fd1578": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "83f7c56af33f4d05bbc050f6a452ae41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "852ad25b40764aa69c1478b1fb0af4db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a850720e5569425897b4ce5993cc1416",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_903407a2f4e54b82b3fe50ef91a8d1f6",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡466k/466kâ€‡[00:00&lt;00:00,â€‡17.5MB/s]"
      }
     },
     "8b670341beaa48c3be2691eba67ca4c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_76894ca1f3204d7abc4011f3d0b651ba",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_6da7c8102b2a4d5b8c78501b7196a279",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡268M/268Mâ€‡[00:03&lt;00:00,â€‡112MB/s]"
      }
     },
     "8bfb01ba7f344287aa65bd4ab747c055": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c32ca99ce75426f926cf87310be5e1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e52c0f124f948109af55c6312894790": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "903407a2f4e54b82b3fe50ef91a8d1f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9286dca4e280418494f912e99e7ac4cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "94acd96a759c4fb08fae26d262a980de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9577c67a067647fb9c8577cf2ea88bdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_31a40d2df05d468dab412c38b8fb88ae",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c5ffbb35174f4f1da86988a6682ac5b8",
       "tabbable": null,
       "tooltip": null,
       "value": 231508.0
      }
     },
     "a0f9484c223147bc968f0087be0a7f82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a850720e5569425897b4ce5993cc1416": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9f79804eb7543749f92b87c198e1db7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5d4070a3050b4e9db4accd3d38d8781a",
        "IPY_MODEL_f40b0be3033a4f6f89454b538630a6a6",
        "IPY_MODEL_5930f9a01f124df095ddfa0a9d66d9d9"
       ],
       "layout": "IPY_MODEL_53fb2f41ba4c4236823e4730e14c5485",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ac2e0a0ab1c9441a8e92ca56d107832f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6b2c318e66fd429ba18c98d7b5eabbc6",
        "IPY_MODEL_9577c67a067647fb9c8577cf2ea88bdb",
        "IPY_MODEL_aebcd99a468343acb6eeea4a7b3b1b26"
       ],
       "layout": "IPY_MODEL_54d8fd79cc3a444aa143ca2d0bccf53b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "adf7a1aa08d1456bb7f723abc5601909": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_705c1109473c4667bd937a368254dcd9",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_8e52c0f124f948109af55c6312894790",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:â€‡100%"
      }
     },
     "adf871cd5c0d455987c71fa65f8929bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f820a3af071c4d99b6929b2cfcd2f16c",
       "max": 267954768.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9286dca4e280418494f912e99e7ac4cb",
       "tabbable": null,
       "tooltip": null,
       "value": 267954768.0
      }
     },
     "aebcd99a468343acb6eeea4a7b3b1b26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e2980dd673784504a74e3e009651e407",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_7b6792d1831244eea821066680fd1578",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡4.70MB/s]"
      }
     },
     "bf32510130c540628dc1fa649ec73916": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_adf7a1aa08d1456bb7f723abc5601909",
        "IPY_MODEL_adf871cd5c0d455987c71fa65f8929bb",
        "IPY_MODEL_8b670341beaa48c3be2691eba67ca4c7"
       ],
       "layout": "IPY_MODEL_cb51650333dc4707be5b098a63987963",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c5ffbb35174f4f1da86988a6682ac5b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c8039e6e170b49e887de961b10890812": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cb51650333dc4707be5b098a63987963": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e21ee4a2daf04bb8910505b2d493cca3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1b3f63a5282449698f9c0dc7f27ed8fb",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_ec1bc933da0648acb64756254cbf979d",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:â€‡100%"
      }
     },
     "e2980dd673784504a74e3e009651e407": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6f79bc649f14b59ab2780c269ca9d8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ec1bc933da0648acb64756254cbf979d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f1dc6e09b6244270acf7d94b7776510c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f3f76e03857e4945ac35828f00e4b764": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6e45da5bec834a57a208e3f47db9cb61",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c8039e6e170b49e887de961b10890812",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json:â€‡100%"
      }
     },
     "f40b0be3033a4f6f89454b538630a6a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5c39e53cab064625aae044f4794880e9",
       "max": 48.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e6f79bc649f14b59ab2780c269ca9d8d",
       "tabbable": null,
       "tooltip": null,
       "value": 48.0
      }
     },
     "f820a3af071c4d99b6929b2cfcd2f16c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9fae800ab044116852c2954a652d20e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_83f7c56af33f4d05bbc050f6a452ae41",
       "max": 483.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0b76f4cb3bff44a8b70fa83348260301",
       "tabbable": null,
       "tooltip": null,
       "value": 483.0
      }
     },
     "fffa980ad107493db2f739b1a5c331ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
